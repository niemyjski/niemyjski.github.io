<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Community Server on Blake Niemyjski</title><link>https://blakeniemyjski.com/categories/community-server/</link><description>Recent content in Community Server on Blake Niemyjski</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 14 May 2009 10:00:00 -0600</lastBuildDate><atom:link href="https://blakeniemyjski.com/categories/community-server/index.xml" rel="self" type="application/rss+xml"/><item><title>How-to: Protect your Telligent Community website from spammers</title><link>https://blakeniemyjski.com/blog/how-to-protect-your-telligent-community-website-from-spammers/</link><pubDate>Thu, 14 May 2009 10:00:00 -0600</pubDate><guid>https://blakeniemyjski.com/blog/how-to-protect-your-telligent-community-website-from-spammers/</guid><description>One should always be aware that your site could be attacked by spam bots if you don&amp;rsquo;t take the proper precautions. The easiest and quickest way to help prevent 500+ spam users from joining your site is to configure the default options to make it harder for spam bots to create accounts. Please note that this can also reduce the number of registrations on your site due to the extra steps it takes to register.</description></item><item><title>How-to: protect your Telligent Community website from rouge spiders with a robots text file</title><link>https://blakeniemyjski.com/blog/how-to-protect-your-telligent-community-website-from-rouge-spiders-with-a-robots-text-file/</link><pubDate>Wed, 13 May 2009 00:00:00 -0600</pubDate><guid>https://blakeniemyjski.com/blog/how-to-protect-your-telligent-community-website-from-rouge-spiders-with-a-robots-text-file/</guid><description>Over the course of the past two years, I have worked on a number of Community Server sites. The goal of these tips are to share useful information about Telligent&amp;rsquo;s Community platform. There are a few ways you can protect yourself from rouge search bots from stealing your content and bringing down your site.
The easiest way is to setup a robots text file, which will tell search engines to ignore certain files or directories.</description></item></channel></rss>